{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie Review Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1w6_ogL0DMlp7kgavZHWHjWS5rI0xCF3a",
      "authorship_tag": "ABX9TyNiBnM1jD7rN8X1JCqKdwAg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ToluClassics/Movie-Review-Sentiment-Analysis/blob/master/Movie_Review_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9zN9j6VBhG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_path = '/content/drive/My Drive/Sentiment Analysis/labels.txt'\n",
        "reviews_path = '/content/drive/My Drive/Sentiment Analysis/reviews.txt'\n",
        "\n",
        "file = open(reviews_path,'r')\n",
        "reviews_list = list(map(lambda x:x[:-1],file.readlines()))\n",
        "\n",
        "file = open(labels_path,'r')\n",
        "labels_list = list(map(lambda x:x[:-1].upper(),file.readlines()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XELQO6t-LZIf",
        "colab_type": "code",
        "outputId": "c6dfe37a-cba9-4074-d09f-28d03f5036f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Number of Labels: \"+str(len(labels_list)))\n",
        "\n",
        "print(\"Number of Reviews: \"+ str(len(reviews_list)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Labels: 25000\n",
            "Number of Reviews: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISdbcAHsLqWx",
        "colab_type": "code",
        "outputId": "921b9a64-76b3-4103-b640-f7793351067b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#We create a function that  takes in the index and outputs the  label and review\n",
        "\n",
        "def pretty_print_review_and_label(i):\n",
        "  print(labels_list[i] + '\\t:\\t' + reviews_list[i])\n",
        "\n",
        "print(\"labels.txt \\t : \\t reviews.txt\\n\")\n",
        "pretty_print_review_and_label(2137)\n",
        "pretty_print_review_and_label(12816)\n",
        "pretty_print_review_and_label(6267)\n",
        "pretty_print_review_and_label(21934)\n",
        "pretty_print_review_and_label(5297)\n",
        "pretty_print_review_and_label(4998)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels.txt \t : \t reviews.txt\n",
            "\n",
            "NEGATIVE\t:\tthis movie is terrible but it has some good effects .  \n",
            "POSITIVE\t:\tadrian pasdar is excellent is this film . he makes a fascinating woman .  \n",
            "NEGATIVE\t:\tcomment this movie is impossible . is terrible  very improbable  bad interpretation e direction . not look       \n",
            "POSITIVE\t:\texcellent episode movie ala pulp fiction .  days   suicides . it doesnt get more depressing than this . movie rating     music rating       \n",
            "NEGATIVE\t:\tif you haven  t seen this  it  s terrible . it is pure trash . i saw this about   years ago  and i  m still screwed up from it .  \n",
            "POSITIVE\t:\tthis schiffer guy is a real genius  the movie is of excellent quality and both entertaining and educating .  br    br   i didn  t know what a weather girl was before i learned it here .  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37QHrHVUWBqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiaxfnoTOtPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a counter object to house all the words in the positive or negative \n",
        "\n",
        "\n",
        "positive_count = Counter()\n",
        "negative_count = Counter()\n",
        "total_count = Counter()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBsfaqB8WgwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(reviews_list)):\n",
        "  if labels_list[i] == \"NEGATIVE\":\n",
        "    for word in str(reviews_list[i]).split(' '):\n",
        "      negative_count[word] += 1\n",
        "      total_count[word] += 1\n",
        "  else:\n",
        "      for word in str(reviews_list[i]).split(' '):\n",
        "        positive_count[word] += 1\n",
        "        total_count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBbNHB6CXY-m",
        "colab_type": "code",
        "outputId": "9dee6c93-1ef5-40ad-d3c2-f0b2cd76fd76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#Print out the most common words used in the positive reviews\n",
        "\n",
        "positive_count.most_common(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', 550468),\n",
              " ('the', 173324),\n",
              " ('.', 159654),\n",
              " ('and', 89722),\n",
              " ('a', 83688),\n",
              " ('of', 76855),\n",
              " ('to', 66746),\n",
              " ('is', 57245),\n",
              " ('in', 50215),\n",
              " ('br', 49235)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUbwUbQSYiW7",
        "colab_type": "code",
        "outputId": "6ee44519-aed2-4297-f43c-c705f592cfe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#Print out the most common words used in the Negative reviews\n",
        "\n",
        "negative_count.most_common(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', 561462),\n",
              " ('.', 167538),\n",
              " ('the', 163389),\n",
              " ('a', 79321),\n",
              " ('and', 74385),\n",
              " ('of', 69009),\n",
              " ('to', 68974),\n",
              " ('br', 52637),\n",
              " ('is', 50083),\n",
              " ('it', 48327)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqkrOvDZZVM8",
        "colab_type": "code",
        "outputId": "7c8060a6-9012-48dc-8786-4aa9ec7e36f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''As you can see, common words like \"the\" appear very often in both positive \n",
        "and negative reviews. Instead of finding the most common words in positive or negative \n",
        "reviews, what you really want are the words found in positive reviews more often than in negative reviews, and vice versa. To accomplish this, you'll \n",
        "need to calculate the **ratios** of word usage between positive and negative reviews.'''"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As you can see, common words like \"the\" appear very often in both positive \\nand negative reviews. Instead of finding the most common words in positive or negative \\nreviews, what you really want are the words found in positive reviews more often than in negative reviews, and vice versa. To accomplish this, you\\'ll \\nneed to calculate the **ratios** of word usage between positive and negative reviews.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXDfwqI1aXva",
        "colab_type": "code",
        "outputId": "6ae68d7a-f737-407f-cefd-363d08b877c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#Calculate the positive negative ratios of words that exist more than 100 times in the total count\n",
        "pos_neg_ratios = Counter()\n",
        "\n",
        "for word,count in total_count.most_common():\n",
        "  if count > 100:\n",
        "    pos_neg_ratio_value = positive_count[word]/float((negative_count[word] +1))\n",
        "    pos_neg_ratios[word] = pos_neg_ratio_value\n",
        "\n",
        "pos_neg_ratios.most_common(10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('edie', 109.0),\n",
              " ('paulie', 59.0),\n",
              " ('felix', 23.4),\n",
              " ('polanski', 16.833333333333332),\n",
              " ('matthau', 16.555555555555557),\n",
              " ('victoria', 14.6),\n",
              " ('mildred', 13.5),\n",
              " ('gandhi', 12.666666666666666),\n",
              " ('flawless', 11.6),\n",
              " ('superbly', 9.583333333333334)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoIaBjKXdWvU",
        "colab_type": "code",
        "outputId": "af902c70-8522-4f51-ece0-4dd116558997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
        "print(\"Pos-to-neg ratio for 'great' = {}\".format(pos_neg_ratios[\"great\"]))\n",
        "print(\"Pos-to-neg ratio for 'bad' = {}\".format(pos_neg_ratios[\"bad\"]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pos-to-neg ratio for 'the' = 1.0607993145235326\n",
            "Pos-to-neg ratio for 'great' = 2.4305187429004165\n",
            "Pos-to-neg ratio for 'bad' = 0.2576330721426641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZsBPfaAgHYL",
        "colab_type": "text"
      },
      "source": [
        "Looking closely at the values you just calculated, we see the following:\n",
        "\n",
        "* Words that you would expect to see more often in positive reviews – like \"amazing\" – have a ratio greater than 1. The more skewed a word is toward postive, the farther from 1 its positive-to-negative ratio  will be.\n",
        "* Words that you would expect to see more often in negative reviews – like \"terrible\" – have positive values that are less than 1. The more skewed a word is toward negative, the closer to zero its positive-to-negative ratio will be.\n",
        "* Neutral words, which don't really convey any sentiment because you would expect to see them in all sorts of reviews – like \"the\" – have values very close to 1. A perfectly neutral word – one that was used in exactly the same number of positive reviews as negative reviews – would be almost exactly 1. The `+1` we suggested you add to the denominator slightly biases words toward negative, but it won't matter because it will be a tiny bias and later we'll be ignoring words that are too close to neutral anyway."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOFbbW4bfahO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Go through all the ratios you calculated and convert them to logarithms. (i.e. use np.log(ratio))\n",
        "\n",
        "for word,ratio in pos_neg_ratios.most_common():\n",
        "  if ratio > 1:\n",
        "    pos_neg_ratios[word] = np.log(ratio)\n",
        "  else:\n",
        "    pos_neg_ratios[word] = -np.log(1/(ratio+0.01))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTerODCSh-Gt",
        "colab_type": "code",
        "outputId": "12ad00a2-2a22-4ff0-8dba-7aebbf68e0f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#Most common positive words\n",
        "pos_neg_ratios.most_common(20)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('edie', 4.6913478822291435),\n",
              " ('paulie', 4.07753744390572),\n",
              " ('felix', 3.152736022363656),\n",
              " ('polanski', 2.8233610476132043),\n",
              " ('matthau', 2.80672172860924),\n",
              " ('victoria', 2.681021528714291),\n",
              " ('mildred', 2.6026896854443837),\n",
              " ('gandhi', 2.538973871058276),\n",
              " ('flawless', 2.451005098112319),\n",
              " ('superbly', 2.26002547857525),\n",
              " ('perfection', 2.159484249353372),\n",
              " ('astaire', 2.1400661634962708),\n",
              " ('captures', 2.038619547159581),\n",
              " ('voight', 2.030170492673053),\n",
              " ('wonderfully', 2.0218960560332353),\n",
              " ('powell', 1.978345424808467),\n",
              " ('brosnan', 1.9547990964725592),\n",
              " ('lily', 1.9203768470501485),\n",
              " ('bakshi', 1.9029851043382795),\n",
              " ('lincoln', 1.9014583864844796)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCy5n58ii5Mx",
        "colab_type": "code",
        "outputId": "40949857-e9bd-4019-cbdd-66493f06dd5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#Most common Negative words\n",
        "list(reversed(pos_neg_ratios.most_common()))[:20]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('boll', -4.07781526027089),\n",
              " ('uwe', -3.921875301871158),\n",
              " ('seagal', -3.320250105858192),\n",
              " ('unwatchable', -3.0269848170580955),\n",
              " ('stinker', -2.9876839403711624),\n",
              " ('mst', -2.775383321170797),\n",
              " ('incoherent', -2.7641396677532537),\n",
              " ('unfunny', -2.5545257844967644),\n",
              " ('waste', -2.4907515123361046),\n",
              " ('blah', -2.4475792789485005),\n",
              " ('horrid', -2.371577964480997),\n",
              " ('pointless', -2.345107387713634),\n",
              " ('atrocious', -2.3187369339642556),\n",
              " ('redeeming', -2.2667790015910296),\n",
              " ('prom', -2.2601040980178784),\n",
              " ('drivel', -2.247602958576693),\n",
              " ('lousy', -2.2118080125207054),\n",
              " ('worst', -2.1930856334332267),\n",
              " ('laughable', -2.172468615469592),\n",
              " ('awful', -2.1385076866397488)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asjML9Ushxp-",
        "colab_type": "code",
        "outputId": "2ca13a91-07c4-4019-f589-eb481a04c16f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
        "print(\"Pos-to-neg ratio for 'great' = {}\".format(pos_neg_ratios[\"great\"]))\n",
        "print(\"Pos-to-neg ratio for 'bad' = {}\".format(pos_neg_ratios[\"bad\"]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pos-to-neg ratio for 'the' = 0.05902269426102881\n",
            "Pos-to-neg ratio for 'great' = 0.8881047090146459\n",
            "Pos-to-neg ratio for 'bad' = -1.3181383703873577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_EDaH4ilEKC",
        "colab_type": "text"
      },
      "source": [
        "Building a **Neural Network** with 2 layers (Input Layer, Hidden Layer and Output later)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEzCd4djiLfv",
        "colab_type": "code",
        "outputId": "4aa67680-986f-4321-e704-50e8ebe090c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Create an unordered list from all the words in the review\n",
        "\n",
        "vocabulary = set(total_count.keys())\n",
        "vocab_size = len(vocabulary)\n",
        "\n",
        "vocab_size"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74074"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lR3VY5EmHqL",
        "colab_type": "code",
        "outputId": "6520081c-9742-4bd6-cb51-4bba5ad2023b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Create a row array initialized to zeros and the size with the vocabulary length\n",
        "\n",
        "\n",
        "layer_0 = np.zeros((1,vocab_size))\n",
        "layer_0.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 74074)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Quinp72VnWo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next we create a dictionary that maps the each work and its index\n",
        "word_index = {}\n",
        "\n",
        "for i,word in enumerate(vocabulary):\n",
        "   word_index[word]=i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydgaz-NAou1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We are going to create a function to create output layer by using the count of words in each review\n",
        "\n",
        "def update_input_layer(review):\n",
        "\n",
        "  global layer_0\n",
        "  #clear the variable layer_0\n",
        "  layer_0 *= 0\n",
        "\n",
        "  for word in review.split(' '):\n",
        "    layer_0[0][word_index[word]]+=1\n",
        "  \n",
        "  return layer_0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbvLhawwpEaT",
        "colab_type": "code",
        "outputId": "4febad13-1164-4ab6-db88-2f337d40451a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "update_input_layer(reviews_list[2137])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DUuNdv7rD0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define a function to encode the output label\n",
        "\n",
        "def label_encoding(label):\n",
        "  \n",
        "  if label == 'POSITIVE':\n",
        "    label_encod = 1\n",
        "  else:\n",
        "    label_encod = 0\n",
        "\n",
        "  return label_encod"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dym8LS1NtJQS",
        "colab_type": "code",
        "outputId": "bb83fa92-1c24-4ba5-f982-54aa95e2c9d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "label_encoding(labels_list[100])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pwl8v_BkKeXD",
        "colab_type": "text"
      },
      "source": [
        "**Define the Neural Network Architecture in Pytorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8gxRGcctQ7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "\n",
        "    #FIrst Linear Layer with 74074 nodes, mid layer with\n",
        "    self.fc1 = nn.Linear(74074,10)\n",
        "    self.fc2 = nn.Linear(10,1)\n",
        "    self.sig = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.sig(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.sig(x)\n",
        "    return x \n",
        "\n",
        "model = Net()\n",
        "model = model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSHdkxsvy4Mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tenser = update_input_layer(reviews_list[2137])\n",
        "tenser = torch.from_numpy(tenser)\n",
        "\n",
        "\n",
        "a = model(tenser.float().cuda())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urs4-9z2_XJj",
        "colab_type": "code",
        "outputId": "12ab7d99-c8d5-442d-bd3c-9a6f84f69a58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "float(a)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39745715260505676"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78aozp4mya80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#It's recommended that you use cross-entropy loss for classification.\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etWLTk5lEHCP",
        "colab_type": "text"
      },
      "source": [
        "Training the 2 layer Neural Network in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSOlWuo65QqB",
        "colab_type": "code",
        "outputId": "698dbcc6-8aec-423e-c0b0-e2a2ee6056f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Algorithm to train the network\n",
        "import time,sys\n",
        "n_epochs = 1\n",
        "\n",
        "model.train()\n",
        "\n",
        "assert(len(reviews_list) == len(labels_list))\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  correct_so_far = 0\n",
        "  start = time.time()\n",
        "\n",
        "  for i in range(len(reviews_list)):\n",
        "    #optimizer.zero_grad()\n",
        "\n",
        "    layer_0 = np.zeros((1,vocab_size))\n",
        "\n",
        "    layer_0 = update_input_layer(reviews_list[i])\n",
        "\n",
        "    layer_0 = torch.from_numpy(layer_0)\n",
        "\n",
        "    output = model(layer_0.float().cuda())\n",
        "\n",
        "    y = label_encoding(labels_list[i])\n",
        "\n",
        "    loss = output-y\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if abs(loss) < 0.5:\n",
        "      correct_so_far += 1\n",
        "\n",
        "    elapsed_time = float(time.time() - start)\n",
        "    reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
        "\n",
        "\n",
        "    sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(reviews_list)))[:4] \\\n",
        "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
        "                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n",
        "                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
        "    if(i % 2500 == 0):\n",
        "      print(\"\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n",
            "Progress:10.0% Speed(reviews/sec):366.6 #Correct:1250 #Trained:2501 Training Accuracy:49.9%\n",
            "Progress:20.0% Speed(reviews/sec):368.0 #Correct:2500 #Trained:5001 Training Accuracy:49.9%\n",
            "Progress:30.0% Speed(reviews/sec):369.2 #Correct:3750 #Trained:7501 Training Accuracy:49.9%\n",
            "Progress:40.0% Speed(reviews/sec):370.3 #Correct:5000 #Trained:10001 Training Accuracy:49.9%\n",
            "Progress:50.0% Speed(reviews/sec):370.8 #Correct:6250 #Trained:12501 Training Accuracy:49.9%\n",
            "Progress:60.0% Speed(reviews/sec):371.1 #Correct:7500 #Trained:15001 Training Accuracy:49.9%\n",
            "Progress:70.0% Speed(reviews/sec):371.6 #Correct:8750 #Trained:17501 Training Accuracy:49.9%\n",
            "Progress:80.0% Speed(reviews/sec):371.8 #Correct:10000 #Trained:20001 Training Accuracy:49.9%\n",
            "Progress:90.0% Speed(reviews/sec):369.5 #Correct:11250 #Trained:22501 Training Accuracy:49.9%\n",
            "Progress:99.9% Speed(reviews/sec):366.7 #Correct:12500 #Trained:25000 Training Accuracy:50.0%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGVkJDQxEE1R",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhGCIRCiEqV1",
        "colab_type": "text"
      },
      "source": [
        "Training the Neural Network the conventional way using the input layer as a count of all the words in each movie review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2d5f5Ts-qqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "# Encapsulate our neural network in a class\n",
        "class SentimentNetwork:\n",
        "    def __init__(self, reviews, labels, hidden_nodes = 10, learning_rate = 0.1):\n",
        "        \"\"\"Create a SentimenNetwork with the given settings\n",
        "        Args:\n",
        "            reviews(list) - List of reviews used for training\n",
        "            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews\n",
        "            hidden_nodes(int) - Number of nodes to create in the hidden layer\n",
        "            learning_rate(float) - Learning rate to use while training\n",
        "        \n",
        "        \"\"\"\n",
        "        # Assign a seed to our random number generator to ensure we get\n",
        "        # reproducable results during development \n",
        "        np.random.seed(1)\n",
        "\n",
        "        # process the reviews and their associated labels so that everything\n",
        "        # is ready for training\n",
        "        self.pre_process_data(reviews, labels)\n",
        "        \n",
        "        # Build the network to have the number of hidden nodes and the learning rate that\n",
        "        # were passed into this initializer. Make the same number of input nodes as\n",
        "        # there are vocabulary words and create a single output node.\n",
        "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
        "\n",
        "    def pre_process_data(self, reviews, labels):\n",
        "        \n",
        "        review_vocab = set()\n",
        "        # populate review_vocab with all of the words in the given reviews\n",
        "        #       Remember to split reviews into individual words \n",
        "        #       using \"split(' ')\" instead of \"split()\".\n",
        "        for i in range(len(reviews)):\n",
        "            for word in reviews[i].split(' '):\n",
        "                review_vocab.add(word)\n",
        "        \n",
        "        # Convert the vocabulary set to a list so we can access words via indices\n",
        "        self.review_vocab = list(review_vocab)\n",
        "        \n",
        "        label_vocab = set()\n",
        "        # : populate label_vocab with all of the words in the given labels.\n",
        "        #       There is no need to split the labels because each one is a single word.\n",
        "        for label in labels:\n",
        "            label_vocab.add(label)\n",
        "        \n",
        "        # Convert the label vocabulary set to a list so we can access labels via indices\n",
        "        self.label_vocab = list(label_vocab)\n",
        "        \n",
        "        # Store the sizes of the review and label vocabularies.\n",
        "        self.review_vocab_size = len(self.review_vocab)\n",
        "        self.label_vocab_size = len(self.label_vocab)\n",
        "        \n",
        "        # Create a dictionary of words in the vocabulary mapped to index positions\n",
        "        self.word2index = {}\n",
        "        #  : populate self.word2index with indices for all the words in self.review_vocab\n",
        "        #       like you saw earlier in the notebook\n",
        "        for i,word in enumerate(review_vocab):\n",
        "            self.word2index[word] = i\n",
        "        \n",
        "        # Create a dictionary of labels mapped to index positions\n",
        "        self.label2index = {}\n",
        "        #  : do the same thing you did for self.word2index and self.review_vocab, \n",
        "        #       but for self.label2index and self.label_vocab instead\n",
        "        for i,label in enumerate(label_vocab):\n",
        "            self.label2index[word] = i \n",
        "        \n",
        "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
        "        # Store the number of nodes in input, hidden, and output layers.\n",
        "        self.input_nodes = input_nodes\n",
        "        self.hidden_nodes = hidden_nodes\n",
        "        self.output_nodes = output_nodes\n",
        "\n",
        "        # Store the learning rate\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Initialize weights\n",
        "        \n",
        "        #  : initialize self.weights_0_1 as a matrix of zeros. These are the weights between\n",
        "        #       the input layer and the hidden layer.\n",
        "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
        "        \n",
        "        #  : initialize self.weights_1_2 as a matrix of random values. \n",
        "        #       These are the weights between the hidden layer and the output layer.\n",
        "        self.weights_1_2 = np.random.normal(0.0,self.output_nodes**-0.5,(self.hidden_nodes,self.output_nodes))\n",
        "        \n",
        "        #  : Create the input layer, a two-dimensional matrix with shape \n",
        "        #       1 x input_nodes, with all values initialized to zero\n",
        "        self.layer_0 = np.zeros((1,input_nodes))\n",
        "    \n",
        "        \n",
        "    def update_input_layer(self,review):\n",
        "        #  : You can copy most of the code you wrote for update_input_layer \n",
        "        #       earlier in this notebook. \n",
        "        #\n",
        "        #       However, MAKE SURE YOU CHANGE ALL VARIABLES TO REFERENCE\n",
        "        #       THE VERSIONS STORED IN THIS OBJECT, NOT THE GLOBAL OBJECTS.\n",
        "        #       For example, replace \"layer_0 *= 0\" with \"self.layer_0 *= 0\"\n",
        "        self.layer_0 *= 0\n",
        "        for word in review.split(\" \"):\n",
        "            if word in self.word2index.keys():\n",
        "                self.layer_0[0][self.word2index[word]]+=1\n",
        "                \n",
        "    def get_target_for_label(self,label):\n",
        "        #  : Copy the code you wrote for get_target_for_label \n",
        "        #       earlier in this notebook. \n",
        "        if label == 'POSITIVE':\n",
        "            label_encod = 1\n",
        "        else:\n",
        "            label_encod = 0\n",
        "    \n",
        "        return label_encod\n",
        "        \n",
        "    def sigmoid(self,x):\n",
        "        #  : Return the result of calculating the sigmoid activation function\n",
        "        #       shown in the lectures\n",
        "        return (1/(1+np.exp(-x)))\n",
        "    \n",
        "    def sigmoid_output_2_derivative(self,output):\n",
        "        #  : Return the derivative of the sigmoid activation function, \n",
        "        #       where \"output\" is the original output from the sigmoid fucntion \n",
        "        return (output*(1-output))\n",
        "\n",
        "    def train(self, training_reviews, training_labels):\n",
        "        \n",
        "        # make sure out we have a matching number of reviews and labels\n",
        "        assert(len(training_reviews) == len(training_labels))\n",
        "        \n",
        "        # Keep track of correct predictions to display accuracy during training \n",
        "        correct_so_far = 0\n",
        "        \n",
        "        # Remember when we started for printing time statistics\n",
        "        start = time.time()\n",
        "\n",
        "        # loop through all the given reviews and run a forward and backward pass,\n",
        "        # updating weights for every item\n",
        "        for i in range(len(training_reviews)):\n",
        "            \n",
        "            #  : Get the next review and its correct label\n",
        "            review = training_reviews[i]\n",
        "            label = training_labels[i]\n",
        "            #  : Implement the forward pass through the network. \n",
        "            #       That means use the given review to update the input layer, \n",
        "            #       then calculate values for the hidden layer,\n",
        "            #       and finally calculate the output layer.\n",
        "            # \n",
        "            #       Do not use an activation function for the hidden layer,\n",
        "            #       but use the sigmoid activation function for the output layer.\n",
        "            self.update_input_layer(review)\n",
        "            \n",
        "            layer_1 = np.dot(self.layer_0,self.weights_0_1)\n",
        "            \n",
        "            layer_2 = self.sigmoid(np.dot(layer_1,self.weights_1_2))\n",
        "            \n",
        "            #  : Implement the back propagation pass here. \n",
        "            #       That means calculate the error for the forward pass's prediction\n",
        "            #       and update the weights in the network according to their\n",
        "            #       contributions toward the error, as calculated via the\n",
        "            #       gradient descent and back propagation algorithms you \n",
        "            #       learned in class.\n",
        "            layer_2_error = layer_2 - self.get_target_for_label(label)\n",
        "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
        "            \n",
        "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T)\n",
        "            layer_1_delta = layer_1_error\n",
        "            \n",
        "            self.weights_0_1 -= self.learning_rate*self.layer_0.T.dot(layer_1_delta)\n",
        "            self.weights_1_2 -= self.learning_rate* (np.dot(layer_1.T,layer_2_delta))\n",
        "            \n",
        "            #  : Keep track of correct predictions. To determine if the prediction was\n",
        "            #       correct, check that the absolute value of the output error \n",
        "            #       is less than 0.5. If so, add one to the correct_so_far count.\n",
        "            if abs(layer_2_error) < 0.5:\n",
        "                correct_so_far += 1\n",
        "                \n",
        "            \n",
        "            # For debug purposes, print out our prediction accuracy and speed \n",
        "            # throughout the training process. \n",
        "\n",
        "            elapsed_time = float(time.time() - start)\n",
        "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
        "            \n",
        "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] \\\n",
        "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
        "                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n",
        "                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
        "            if(i % 2500 == 0):\n",
        "                print(\"\")\n",
        "    \n",
        "    def test(self, testing_reviews, testing_labels):\n",
        "        \"\"\"\n",
        "        Attempts to predict the labels for the given testing_reviews,\n",
        "        and uses the test_labels to calculate the accuracy of those predictions.\n",
        "        \"\"\"\n",
        "        \n",
        "        # keep track of how many correct predictions we make\n",
        "        correct = 0\n",
        "\n",
        "        # we'll time how many predictions per second we make\n",
        "        start = time.time()\n",
        "\n",
        "        # Loop through each of the given reviews and call run to predict\n",
        "        # its label. \n",
        "        for i in range(len(testing_reviews)):\n",
        "            pred = self.run(testing_reviews[i])\n",
        "            if(pred == testing_labels[i]):\n",
        "                correct += 1\n",
        "            \n",
        "            # For debug purposes, print out our prediction accuracy and speed \n",
        "            # throughout the prediction process. \n",
        "\n",
        "            elapsed_time = float(time.time() - start)\n",
        "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
        "            \n",
        "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
        "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
        "                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\n",
        "                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
        "    \n",
        "    def run(self, review):\n",
        "        \"\"\"\n",
        "        Returns a POSITIVE or NEGATIVE prediction for the given review.\n",
        "        \"\"\"\n",
        "        #  : Run a forward pass through the network, like you did in the\n",
        "        #       \"train\" function. That means use the given review to \n",
        "        #       update the input layer, then calculate values for the hidden layer,\n",
        "        #       and finally calculate the output layer.\n",
        "        #\n",
        "        #       Note: The review passed into this function for prediction \n",
        "        #             might come from anywhere, so you should convert it \n",
        "        #             to lower case prior to using it.\n",
        "        \n",
        "        self.update_input_layer(review)\n",
        "            \n",
        "        layer_1 = np.dot(self.layer_0,self.weights_0_1)\n",
        "            \n",
        "        layer_2 = self.sigmoid(np.dot(layer_1,self.weights_1_2))\n",
        "        \n",
        "        #  : The output layer should now contain a prediction. \n",
        "        #       Return `POSITIVE` for predictions greater-than-or-equal-to `0.5`, \n",
        "        #       and `NEGATIVE` otherwise.\n",
        "        \n",
        "        if layer_2[0] >= 0.5:\n",
        "            return 'POSITIVE'\n",
        "        else:\n",
        "            return 'NEGATIVE'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkzdWdJWNbFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp = SentimentNetwork(reviews_list[:-1000],labels_list[:-1000], learning_rate=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AnONE3YNok6",
        "colab_type": "code",
        "outputId": "952387d4-3993-4885-ecba-4360e73c6f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#training the model with the default learning rate gives a training accuracy of 49%\n",
        "mlp.train(reviews_list[:-1000],labels_list[:-1000])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n",
            "Progress:10.4% Speed(reviews/sec):215.5 #Correct:1250 #Trained:2501 Training Accuracy:49.9%\n",
            "Progress:20.8% Speed(reviews/sec):215.1 #Correct:2500 #Trained:5001 Training Accuracy:49.9%\n",
            "Progress:31.2% Speed(reviews/sec):215.6 #Correct:3750 #Trained:7501 Training Accuracy:49.9%\n",
            "Progress:41.6% Speed(reviews/sec):216.6 #Correct:5000 #Trained:10001 Training Accuracy:49.9%\n",
            "Progress:52.0% Speed(reviews/sec):216.7 #Correct:6250 #Trained:12501 Training Accuracy:49.9%\n",
            "Progress:62.5% Speed(reviews/sec):216.8 #Correct:7500 #Trained:15001 Training Accuracy:49.9%\n",
            "Progress:72.9% Speed(reviews/sec):216.8 #Correct:8750 #Trained:17501 Training Accuracy:49.9%\n",
            "Progress:83.3% Speed(reviews/sec):216.6 #Correct:10000 #Trained:20001 Training Accuracy:49.9%\n",
            "Progress:93.7% Speed(reviews/sec):216.6 #Correct:11250 #Trained:22501 Training Accuracy:49.9%\n",
            "Progress:99.9% Speed(reviews/sec):216.7 #Correct:11999 #Trained:24000 Training Accuracy:49.9%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyr9cdc1N9lh",
        "colab_type": "code",
        "outputId": "645ef405-1466-45db-e550-72a412f6e45f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#training the model with the default learning rate of 0.0001 increases the training accuracy\n",
        "\n",
        "mlp = SentimentNetwork(reviews_list[:-1000],labels_list[:-1000], learning_rate=0.001)\n",
        "mlp.train(reviews_list[:-1000],labels_list[:-1000])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n",
            "Progress:10.4% Speed(reviews/sec):224.1 #Correct:1357 #Trained:2501 Training Accuracy:54.2%\n",
            "Progress:20.8% Speed(reviews/sec):224.9 #Correct:2899 #Trained:5001 Training Accuracy:57.9%\n",
            "Progress:31.2% Speed(reviews/sec):225.8 #Correct:4561 #Trained:7501 Training Accuracy:60.8%\n",
            "Progress:41.6% Speed(reviews/sec):226.3 #Correct:6305 #Trained:10001 Training Accuracy:63.0%\n",
            "Progress:52.0% Speed(reviews/sec):226.2 #Correct:8098 #Trained:12501 Training Accuracy:64.7%\n",
            "Progress:62.5% Speed(reviews/sec):226.1 #Correct:9895 #Trained:15001 Training Accuracy:65.9%\n",
            "Progress:72.9% Speed(reviews/sec):226.2 #Correct:11681 #Trained:17501 Training Accuracy:66.7%\n",
            "Progress:83.3% Speed(reviews/sec):226.4 #Correct:13550 #Trained:20001 Training Accuracy:67.7%\n",
            "Progress:93.7% Speed(reviews/sec):226.2 #Correct:15420 #Trained:22501 Training Accuracy:68.5%\n",
            "Progress:99.9% Speed(reviews/sec):226.4 #Correct:16578 #Trained:24000 Training Accuracy:69.0%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s42Vx_0oF7_5",
        "colab_type": "text"
      },
      "source": [
        "**Training the Neural Network the conventional way using the input layer as a vector that just indicates if a word exists in each movie review**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulFnANV8Ohfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "# Encapsulate our neural network in a class\n",
        "class Second_SentimentNetwork:\n",
        "    def __init__(self, reviews, labels, hidden_nodes = 10, learning_rate = 0.1):\n",
        "        \"\"\"Create a SentimenNetwork with the given settings\n",
        "        Args:\n",
        "            reviews(list) - List of reviews used for training\n",
        "            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews\n",
        "            hidden_nodes(int) - Number of nodes to create in the hidden layer\n",
        "            learning_rate(float) - Learning rate to use while training\n",
        "        \n",
        "        \"\"\"\n",
        "        # Assign a seed to our random number generator to ensure we get\n",
        "        # reproducable results during development \n",
        "        np.random.seed(1)\n",
        "\n",
        "        # process the reviews and their associated labels so that everything\n",
        "        # is ready for training\n",
        "        self.pre_process_data(reviews, labels)\n",
        "        \n",
        "        # Build the network to have the number of hidden nodes and the learning rate that\n",
        "        # were passed into this initializer. Make the same number of input nodes as\n",
        "        # there are vocabulary words and create a single output node.\n",
        "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
        "\n",
        "    def pre_process_data(self, reviews, labels):\n",
        "        \n",
        "        review_vocab = set()\n",
        "        # populate review_vocab with all of the words in the given reviews\n",
        "        #       Remember to split reviews into individual words \n",
        "        #       using \"split(' ')\" instead of \"split()\".\n",
        "        for i in range(len(reviews)):\n",
        "            for word in reviews[i].split(' '):\n",
        "                review_vocab.add(word)\n",
        "        \n",
        "        # Convert the vocabulary set to a list so we can access words via indices\n",
        "        self.review_vocab = list(review_vocab)\n",
        "        \n",
        "        label_vocab = set()\n",
        "        # : populate label_vocab with all of the words in the given labels.\n",
        "        #       There is no need to split the labels because each one is a single word.\n",
        "        for label in labels:\n",
        "            label_vocab.add(label)\n",
        "        \n",
        "        # Convert the label vocabulary set to a list so we can access labels via indices\n",
        "        self.label_vocab = list(label_vocab)\n",
        "        \n",
        "        # Store the sizes of the review and label vocabularies.\n",
        "        self.review_vocab_size = len(self.review_vocab)\n",
        "        self.label_vocab_size = len(self.label_vocab)\n",
        "        \n",
        "        # Create a dictionary of words in the vocabulary mapped to index positions\n",
        "        self.word2index = {}\n",
        "        #  : populate self.word2index with indices for all the words in self.review_vocab\n",
        "        #       like you saw earlier in the notebook\n",
        "        for i,word in enumerate(review_vocab):\n",
        "            self.word2index[word] = i\n",
        "        \n",
        "        # Create a dictionary of labels mapped to index positions\n",
        "        self.label2index = {}\n",
        "        #  : do the same thing you did for self.word2index and self.review_vocab, \n",
        "        #       but for self.label2index and self.label_vocab instead\n",
        "        for i,label in enumerate(label_vocab):\n",
        "            self.label2index[word] = i \n",
        "        \n",
        "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
        "        # Store the number of nodes in input, hidden, and output layers.\n",
        "        self.input_nodes = input_nodes\n",
        "        self.hidden_nodes = hidden_nodes\n",
        "        self.output_nodes = output_nodes\n",
        "\n",
        "        # Store the learning rate\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Initialize weights\n",
        "        \n",
        "        #  : initialize self.weights_0_1 as a matrix of zeros. These are the weights between\n",
        "        #       the input layer and the hidden layer.\n",
        "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
        "        \n",
        "        #  : initialize self.weights_1_2 as a matrix of random values. \n",
        "        #       These are the weights between the hidden layer and the output layer.\n",
        "        self.weights_1_2 = np.random.normal(0.0,self.output_nodes**-0.5,(self.hidden_nodes,self.output_nodes))\n",
        "        \n",
        "        #  : Create the input layer, a two-dimensional matrix with shape \n",
        "        #       1 x input_nodes, with all values initialized to zero\n",
        "        self.layer_0 = np.zeros((1,input_nodes))\n",
        "    \n",
        "        \n",
        "    def update_input_layer(self,review):\n",
        "\n",
        "        #       For example, replace \"layer_0 *= 0\" with \"self.layer_0 *= 0\"\n",
        "        self.layer_0 *= 0\n",
        "        for word in review.split(\" \"):\n",
        "            if word in self.word2index.keys():\n",
        "                self.layer_0[0][self.word2index[word]]=1\n",
        "                \n",
        "    def get_target_for_label(self,label):\n",
        "        #  : Copy the code you wrote for get_target_for_label \n",
        "        #       earlier in this notebook. \n",
        "        if label == 'POSITIVE':\n",
        "            label_encod = 1\n",
        "        else:\n",
        "            label_encod = 0\n",
        "    \n",
        "        return label_encod\n",
        "        \n",
        "    def sigmoid(self,x):\n",
        "        #  : Return the result of calculating the sigmoid activation function\n",
        "        #       shown in the lectures\n",
        "        return (1/(1+np.exp(-x)))\n",
        "    \n",
        "    def sigmoid_output_2_derivative(self,output):\n",
        "        #  : Return the derivative of the sigmoid activation function, \n",
        "        #       where \"output\" is the original output from the sigmoid fucntion \n",
        "        return (output*(1-output))\n",
        "\n",
        "    def train(self, training_reviews, training_labels):\n",
        "        \n",
        "        # make sure out we have a matching number of reviews and labels\n",
        "        assert(len(training_reviews) == len(training_labels))\n",
        "        \n",
        "        # Keep track of correct predictions to display accuracy during training \n",
        "        correct_so_far = 0\n",
        "        \n",
        "        # Remember when we started for printing time statistics\n",
        "        start = time.time()\n",
        "\n",
        "        # loop through all the given reviews and run a forward and backward pass,\n",
        "        # updating weights for every item\n",
        "        for i in range(len(training_reviews)):\n",
        "            \n",
        "            #  : Get the next review and its correct label\n",
        "            review = training_reviews[i]\n",
        "            label = training_labels[i]\n",
        "            #  : Implement the forward pass through the network. \n",
        "            #       That means use the given review to update the input layer, \n",
        "            #       then calculate values for the hidden layer,\n",
        "            #       and finally calculate the output layer.\n",
        "            # \n",
        "            #       Do not use an activation function for the hidden layer,\n",
        "            #       but use the sigmoid activation function for the output layer.\n",
        "            self.update_input_layer(review)\n",
        "            \n",
        "            layer_1 = np.dot(self.layer_0,self.weights_0_1)\n",
        "            \n",
        "            layer_2 = self.sigmoid(np.dot(layer_1,self.weights_1_2))\n",
        "            \n",
        "            #  : Implement the back propagation pass here. \n",
        "            #       That means calculate the error for the forward pass's prediction\n",
        "            #       and update the weights in the network according to their\n",
        "            #       contributions toward the error, as calculated via the\n",
        "            #       gradient descent and back propagation algorithms you \n",
        "            #       learned in class.\n",
        "            layer_2_error = layer_2 - self.get_target_for_label(label)\n",
        "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
        "            \n",
        "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T)\n",
        "            layer_1_delta = layer_1_error\n",
        "            \n",
        "            self.weights_0_1 -= self.learning_rate*self.layer_0.T.dot(layer_1_delta)\n",
        "            self.weights_1_2 -= self.learning_rate* (np.dot(layer_1.T,layer_2_delta))\n",
        "            \n",
        "            #  : Keep track of correct predictions. To determine if the prediction was\n",
        "            #       correct, check that the absolute value of the output error \n",
        "            #       is less than 0.5. If so, add one to the correct_so_far count.\n",
        "            if abs(layer_2_error) < 0.5:\n",
        "                correct_so_far += 1\n",
        "                \n",
        "            \n",
        "            # For debug purposes, print out our prediction accuracy and speed \n",
        "            # throughout the training process. \n",
        "\n",
        "            elapsed_time = float(time.time() - start)\n",
        "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
        "            \n",
        "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] \\\n",
        "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
        "                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n",
        "                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
        "            if(i % 2500 == 0):\n",
        "                print(\"\")\n",
        "    \n",
        "    def test(self, testing_reviews, testing_labels):\n",
        "        \"\"\"\n",
        "        Attempts to predict the labels for the given testing_reviews,\n",
        "        and uses the test_labels to calculate the accuracy of those predictions.\n",
        "        \"\"\"\n",
        "        \n",
        "        # keep track of how many correct predictions we make\n",
        "        correct = 0\n",
        "\n",
        "        # we'll time how many predictions per second we make\n",
        "        start = time.time()\n",
        "\n",
        "        # Loop through each of the given reviews and call run to predict\n",
        "        # its label. \n",
        "        for i in range(len(testing_reviews)):\n",
        "            pred = self.run(testing_reviews[i])\n",
        "            if(pred == testing_labels[i]):\n",
        "                correct += 1\n",
        "            \n",
        "            # For debug purposes, print out our prediction accuracy and speed \n",
        "            # throughout the prediction process. \n",
        "\n",
        "            elapsed_time = float(time.time() - start)\n",
        "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
        "            \n",
        "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
        "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
        "                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\n",
        "                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
        "    \n",
        "    def run(self, review):\n",
        "        \"\"\"\n",
        "        Returns a POSITIVE or NEGATIVE prediction for the given review.\n",
        "        \"\"\"\n",
        "        #  : Run a forward pass through the network, like you did in the\n",
        "        #       \"train\" function. That means use the given review to \n",
        "        #       update the input layer, then calculate values for the hidden layer,\n",
        "        #       and finally calculate the output layer.\n",
        "        #\n",
        "        #       Note: The review passed into this function for prediction \n",
        "        #             might come from anywhere, so you should convert it \n",
        "        #             to lower case prior to using it.\n",
        "        \n",
        "        self.update_input_layer(review)\n",
        "            \n",
        "        layer_1 = np.dot(self.layer_0,self.weights_0_1)\n",
        "            \n",
        "        layer_2 = self.sigmoid(np.dot(layer_1,self.weights_1_2))\n",
        "        \n",
        "        #  : The output layer should now contain a prediction. \n",
        "        #       Return `POSITIVE` for predictions greater-than-or-equal-to `0.5`, \n",
        "        #       and `NEGATIVE` otherwise.\n",
        "        \n",
        "        if layer_2[0] >= 0.5:\n",
        "            return 'POSITIVE'\n",
        "        else:\n",
        "            return 'NEGATIVE'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YZ_-IRaGuRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp = Second_SentimentNetwork(reviews_list[:-1000],labels_list[:-1000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EruBS5-2GyyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "41cc26bf-6281-47a3-ffad-129d7e6f736f"
      },
      "source": [
        "#training the model with the default learning rate gives a training accuracy of 49%\n",
        "mlp.train(reviews_list[:-1000],labels_list[:-1000])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n",
            "Progress:10.4% Speed(reviews/sec):218.1 #Correct:1803 #Trained:2501 Training Accuracy:72.0%\n",
            "Progress:20.8% Speed(reviews/sec):216.8 #Correct:3772 #Trained:5001 Training Accuracy:75.4%\n",
            "Progress:31.2% Speed(reviews/sec):216.8 #Correct:5847 #Trained:7501 Training Accuracy:77.9%\n",
            "Progress:41.6% Speed(reviews/sec):218.5 #Correct:7980 #Trained:10001 Training Accuracy:79.7%\n",
            "Progress:52.0% Speed(reviews/sec):221.6 #Correct:10104 #Trained:12501 Training Accuracy:80.8%\n",
            "Progress:62.5% Speed(reviews/sec):224.2 #Correct:12228 #Trained:15001 Training Accuracy:81.5%\n",
            "Progress:72.9% Speed(reviews/sec):226.1 #Correct:14347 #Trained:17501 Training Accuracy:81.9%\n",
            "Progress:83.3% Speed(reviews/sec):227.6 #Correct:16541 #Trained:20001 Training Accuracy:82.7%\n",
            "Progress:93.7% Speed(reviews/sec):228.9 #Correct:18717 #Trained:22501 Training Accuracy:83.1%\n",
            "Progress:99.9% Speed(reviews/sec):229.5 #Correct:20053 #Trained:24000 Training Accuracy:83.5%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDGxNMjONsmL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8971b716-c899-43c9-c718-58b0f413c596"
      },
      "source": [
        "#training the model with a lower learning rate to see how it affects the accuracy of the model\n",
        "\n",
        "mlp = SentimentNetwork(reviews_list[:-1000],labels_list[:-1000], learning_rate=0.001)\n",
        "mlp.train(reviews_list[:-1000],labels_list[:-1000])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n",
            "Progress:10.4% Speed(reviews/sec):222.6 #Correct:1940 #Trained:2501 Training Accuracy:77.5%\n",
            "Progress:20.8% Speed(reviews/sec):223.2 #Correct:3987 #Trained:5001 Training Accuracy:79.7%\n",
            "Progress:31.2% Speed(reviews/sec):224.2 #Correct:6085 #Trained:7501 Training Accuracy:81.1%\n",
            "Progress:41.6% Speed(reviews/sec):227.9 #Correct:8204 #Trained:10001 Training Accuracy:82.0%\n",
            "Progress:52.0% Speed(reviews/sec):229.9 #Correct:10337 #Trained:12501 Training Accuracy:82.6%\n",
            "Progress:62.5% Speed(reviews/sec):231.4 #Correct:12423 #Trained:15001 Training Accuracy:82.8%\n",
            "Progress:72.9% Speed(reviews/sec):232.3 #Correct:14524 #Trained:17501 Training Accuracy:82.9%\n",
            "Progress:83.3% Speed(reviews/sec):233.0 #Correct:16697 #Trained:20001 Training Accuracy:83.4%\n",
            "Progress:93.7% Speed(reviews/sec):233.5 #Correct:18856 #Trained:22501 Training Accuracy:83.8%\n",
            "Progress:99.9% Speed(reviews/sec):233.6 #Correct:20172 #Trained:24000 Training Accuracy:84.0%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTfBkU8BRYgG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "128e8dd8-bc19-4d9d-e752-589345a8ce6e"
      },
      "source": [
        "mlp.run(reviews_list[10])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'POSITIVE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hugPEo_PFl2",
        "colab_type": "text"
      },
      "source": [
        "We are going to visualize the ratio of each word usage in the positive and negative reviews using the pos_neg_ratios counter object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL_OpvCMOnVI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "76bf7540-4658-4dd9-c3d8-7ca45b212be7"
      },
      "source": [
        "pos_neg_ratios.most_common(20)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('edie', 4.6913478822291435),\n",
              " ('paulie', 4.07753744390572),\n",
              " ('felix', 3.152736022363656),\n",
              " ('polanski', 2.8233610476132043),\n",
              " ('matthau', 2.80672172860924),\n",
              " ('victoria', 2.681021528714291),\n",
              " ('mildred', 2.6026896854443837),\n",
              " ('gandhi', 2.538973871058276),\n",
              " ('flawless', 2.451005098112319),\n",
              " ('superbly', 2.26002547857525),\n",
              " ('perfection', 2.159484249353372),\n",
              " ('astaire', 2.1400661634962708),\n",
              " ('captures', 2.038619547159581),\n",
              " ('voight', 2.030170492673053),\n",
              " ('wonderfully', 2.0218960560332353),\n",
              " ('powell', 1.978345424808467),\n",
              " ('brosnan', 1.9547990964725592),\n",
              " ('lily', 1.9203768470501485),\n",
              " ('bakshi', 1.9029851043382795),\n",
              " ('lincoln', 1.9014583864844796)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOnntC8ZPC6_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "cf576b37-7c16-470b-a606-827c3b74ba1f"
      },
      "source": [
        "list(reversed(pos_neg_ratios.most_common()))[:20]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('boll', -4.07781526027089),\n",
              " ('uwe', -3.921875301871158),\n",
              " ('seagal', -3.320250105858192),\n",
              " ('unwatchable', -3.0269848170580955),\n",
              " ('stinker', -2.9876839403711624),\n",
              " ('mst', -2.775383321170797),\n",
              " ('incoherent', -2.7641396677532537),\n",
              " ('unfunny', -2.5545257844967644),\n",
              " ('waste', -2.4907515123361046),\n",
              " ('blah', -2.4475792789485005),\n",
              " ('horrid', -2.371577964480997),\n",
              " ('pointless', -2.345107387713634),\n",
              " ('atrocious', -2.3187369339642556),\n",
              " ('redeeming', -2.2667790015910296),\n",
              " ('prom', -2.2601040980178784),\n",
              " ('drivel', -2.247602958576693),\n",
              " ('lousy', -2.2118080125207054),\n",
              " ('worst', -2.1930856334332267),\n",
              " ('laughable', -2.172468615469592),\n",
              " ('awful', -2.1385076866397488)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-LpLBiaPepQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bokeh.models import ColumnDataSource, LabelSet\n",
        "from bokeh.plotting import figure, show, output_file\n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI00nTlBPyT-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "outputId": "e0911785-e098-4fcc-bd9a-8f461eef37b3"
      },
      "source": [
        "hist, edges = np.histogram(list(map(lambda x:x[1],pos_neg_ratios.most_common())), density=True, bins=100, normed=True)\n",
        "\n",
        "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
        "           toolbar_location=\"above\",\n",
        "           title=\"Word Positive/Negative Affinity Distribution\")\n",
        "p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=\"#555555\")\n",
        "show(p)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: The normed argument is ignored when density is provided. In future passing both will result in an error.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "\n",
              "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "  var JS_MIME_TYPE = 'application/javascript';\n",
              "  var HTML_MIME_TYPE = 'text/html';\n",
              "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    var script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    var cell = handle.cell;\n",
              "\n",
              "    var id = cell.output_area._bokeh_element_id;\n",
              "    var server_id = cell.output_area._bokeh_server_id;\n",
              "    // Clean up Bokeh references\n",
              "    if (id != null && id in Bokeh.index) {\n",
              "      Bokeh.index[id].model.document.clear();\n",
              "      delete Bokeh.index[id];\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            var id = msg.content.text.trim();\n",
              "            if (id in Bokeh.index) {\n",
              "              Bokeh.index[id].model.document.clear();\n",
              "              delete Bokeh.index[id];\n",
              "            }\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    var output_area = handle.output_area;\n",
              "    var output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      var bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      var script_attrs = bk_div.children[0].attributes;\n",
              "      for (var i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      var toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  \n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded() {\n",
              "    var el = document.getElementById(null);\n",
              "    if (el != null) {\n",
              "      el.textContent = \"BokehJS is loading...\";\n",
              "    }\n",
              "    if (root.Bokeh !== undefined) {\n",
              "      if (el != null) {\n",
              "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(display_loaded, 100)\n",
              "    }\n",
              "  }\n",
              "\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
              "        if (callback != null)\n",
              "          callback();\n",
              "      });\n",
              "    } finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.debug(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(css_urls, js_urls, callback) {\n",
              "    if (css_urls == null) css_urls = [];\n",
              "    if (js_urls == null) js_urls = [];\n",
              "\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
              "\n",
              "    function on_load() {\n",
              "      root._bokeh_is_loading--;\n",
              "      if (root._bokeh_is_loading === 0) {\n",
              "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
              "        run_callbacks()\n",
              "      }\n",
              "    }\n",
              "\n",
              "    function on_error() {\n",
              "      console.error(\"failed to load \" + url);\n",
              "    }\n",
              "\n",
              "    for (var i = 0; i < css_urls.length; i++) {\n",
              "      var url = css_urls[i];\n",
              "      const element = document.createElement(\"link\");\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.rel = \"stylesheet\";\n",
              "      element.type = \"text/css\";\n",
              "      element.href = url;\n",
              "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
              "      document.body.appendChild(element);\n",
              "    }\n",
              "\n",
              "    for (var i = 0; i < js_urls.length; i++) {\n",
              "      var url = js_urls[i];\n",
              "      var element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "  };\n",
              "\n",
              "  function inject_raw_css(css) {\n",
              "    const element = document.createElement(\"style\");\n",
              "    element.appendChild(document.createTextNode(css));\n",
              "    document.body.appendChild(element);\n",
              "  }\n",
              "\n",
              "  \n",
              "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
              "  var css_urls = [];\n",
              "  \n",
              "\n",
              "  var inline_js = [\n",
              "    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "    function(Bokeh) {\n",
              "    \n",
              "    \n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    \n",
              "    if (root.Bokeh !== undefined || force === true) {\n",
              "      \n",
              "    for (var i = 0; i < inline_js.length; i++) {\n",
              "      inline_js[i].call(root, root.Bokeh);\n",
              "    }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(css_urls, js_urls, function() {\n",
              "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "  <div class=\"bk-root\" id=\"05a334cd-d8bb-4b84-bc43-34b902f5758e\" data-root-id=\"1274\"></div>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function embed_document(root) {\n",
              "    \n",
              "  var docs_json = {\"febe4297-df6f-4b07-a174-4e3b85a6c3d6\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1285\",\"type\":\"LinearAxis\"}],\"center\":[{\"id\":\"1289\",\"type\":\"Grid\"},{\"id\":\"1294\",\"type\":\"Grid\"}],\"left\":[{\"id\":\"1290\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"1307\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1275\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1299\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"1277\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1281\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1279\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1283\",\"type\":\"LinearScale\"}},\"id\":\"1274\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"callback\":null,\"data\":{\"left\":{\"__ndarray__\":\"Cvm3za5PEMCZHufvxesPwB5LXkQuOA/AonfVmJaEDsAnpEzt/tANwKzQw0FnHQ3AMf06ls9pDMC2KbLqN7YLwDpWKT+gAgvAv4KgkwhPCsBErxfocJsJwMnbjjzZ5wjATggGkUE0CMDSNH3lqYAHwFhh9DkSzQbA3I1rjnoZBsBhuuLi4mUFwObmWTdLsgTAahPRi7P+A8DwP0jgG0sDwHRsvzSElwLA+Zg2iezjAcB+xa3dVDABwAPyJDK9fADAED04DUuS/78Ylia2Gyv+vyLvFF/sw/y/LEgDCL1c+782ofGwjfX5v0D631lejvi/SFPOAi8n979SrLyr/7/1v1wFq1TQWPS/Zl6Z/aDx8r9wt4emcYrxv3gQdk9CI/C/BNPI8CV47b8YhaVCx6nqvyw3gpRo2+e/QOle5gkN5b9Qmzs4qz7iv8iaMBSZ4N6/8P7pt9tD2b8YY6NbHqfTv4COuf7BFMy/0FYsRkfbwL+AfHw2Moemv4BiuKu4XqY/QFB74yjRwD8AiAicowrMP+DfSioPotM/sHuRhsw+2T+QF9jiidveP7BZj58jPOI/oKeyTYIK5T+Q9dX74NjnP3hD+ak/p+o/aJEcWJ517T+o7x+D/iHwP6CWMdotifE/mD1DMV3w8j+M5FSIjFf0P4SLZt+7vvU/eDJ4Nusl9z9w2YmNGo34P2iAm+RJ9Pk/XCetO3lb+z9Uzr6SqML8P0h10OnXKf4/QBziQAeR/z+c4flLG3wAQBa1gveyLwFAkogLo0rjAUAMXJRO4pYCQIgvHfp5SgNABAOmpRH+A0B+1i5RqbEEQPqpt/xAZQVAdH1AqNgYBkDwUMlTcMwGQGwkUv8HgAdA5vfaqp8zCEBiy2NWN+cIQNye7AHPmglAWHJ1rWZOCkDSRf5Y/gELQE4ZhwSWtQtAyuwPsC1pDEBEwJhbxRwNQMCTIQdd0A1AOmeqsvSDDkC2OjNejDcPQDAOvAkk6w9A1nCi2l1PEECU2mawKakQQFJEK4b1AhFADq7vW8FcEUDMF7QxjbYRQIqBeAdZEBJASOs83SRqEkA=\",\"dtype\":\"float64\",\"shape\":[100]},\"right\":{\"__ndarray__\":\"mR7n78XrD8AeS15ELjgPwKJ31ZiWhA7AJ6RM7f7QDcCs0MNBZx0NwDH9OpbPaQzAtimy6je2C8A6Vik/oAILwL+CoJMITwrARK8X6HCbCcDJ24482ecIwE4IBpFBNAjA0jR95amAB8BYYfQ5Es0GwNyNa456GQbAYbri4uJlBcDm5lk3S7IEwGoT0Yuz/gPA8D9I4BtLA8B0bL80hJcCwPmYNons4wHAfsWt3VQwAcAD8iQyvXwAwBA9OA1Lkv+/GJYmthsr/r8i7xRf7MP8vyxIAwi9XPu/NqHxsI31+b9A+t9ZXo74v0hTzgIvJ/e/Uqy8q/+/9b9cBatU0Fj0v2Zemf2g8fK/cLeHpnGK8b94EHZPQiPwvwTTyPAleO2/GIWlQsep6r8sN4KUaNvnv0DpXuYJDeW/UJs7OKs+4r/ImjAUmeDev/D+6bfbQ9m/GGOjWx6n07+Ajrn+wRTMv9BWLEZH28C/gHx8NjKHpr+AYriruF6mP0BQe+Mo0cA/AIgInKMKzD/g30oqD6LTP7B7kYbMPtk/kBfY4onb3j+wWY+fIzziP6Cnsk2CCuU/kPXV++DY5z94Q/mpP6fqP2iRHFiede0/qO8fg/4h8D+gljHaLYnxP5g9QzFd8PI/jORUiIxX9D+Ei2bfu771P3gyeDbrJfc/cNmJjRqN+D9ogJvkSfT5P1wnrTt5W/s/VM6+kqjC/D9IddDp1yn+P0Ac4kAHkf8/nOH5Sxt8AEAWtYL3si8BQJKIC6NK4wFADFyUTuKWAkCILx36eUoDQAQDpqUR/gNAftYuUamxBED6qbf8QGUFQHR9QKjYGAZA8FDJU3DMBkBsJFL/B4AHQOb32qqfMwhAYstjVjfnCEDcnuwBz5oJQFhyda1mTgpA0kX+WP4BC0BOGYcElrULQMrsD7AtaQxARMCYW8UcDUDAkyEHXdANQDpnqrL0gw5AtjozXow3D0AwDrwJJOsPQNZwotpdTxBAlNpmsCmpEEBSRCuG9QIRQA6u71vBXBFAzBe0MY22EUCKgXgHWRASQEjrPN0kahJABlUBs/DDEkA=\",\"dtype\":\"float64\",\"shape\":[100]},\"top\":{\"__ndarray__\":\"s6auGMn1ZT+zpq4YyfVlPwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALOmrhjJ9WU/AAAAAAAAAAAAAAAAAAAAALOmrhjJ9WU/k6auGMn1ZT8AAAAAAAAAAJOmrhjJ9XU/AAAAAAAAAAAAAAAAAAAAAJOmrhjJ9WU/0qauGMn1dT+Tpq4YyfV1P7OmrhjJ9YU/Bf2C0lZ4gD+zpq4YyfWFP7OmrhjJ9WU/wdGY9Q83kz9fUNpeO3ObPwX9gtJWeJA/s6auGMn1lT/d0Zj1DzeTP8HRmPUPN6M/9GVPzd4Tqj+Je8Q7grSoP/RlT83eE6o/O3JIGwUosT9zD3sTUZGvP/RlT83eE7o/9GVPzd4Tuj+ht+X2LdDAP+gbdGF3pcY/2lQY73k5zz+nXNOsYYfSP6wBwWKVPtQ/xJV3OmQb2z9Z/6EadlviPyTgAZkQXOU/7sBhF6tc6D9YgiEU4F3uP2El8IH0Me4/XSz8TJet6j/wnIMFB5fnP/EzCBg6Kec/9UZePr7m4z89itzRx6vhP+ED4Kq0IdY/9UZePr7m0z+XmrXKouHOP/nrS/TxncU/Zbwjh2yWxD+hOmXwl9K8P/VGXj6+5rM/mzHpzxpGtT/8kDmqJVWnP2W8I4dslqQ/wdGY9Q83oz8qvCOHbJakP/jRmPUPN5M/wdGY9Q83kz8d/YLSVniQP5OmrhjJ9YU/k6auGMn1hT/Spq4YyfVlP5OmrhjJ9WU/0qauGMn1ZT8AAAAAAAAAAJOmrhjJ9WU/0qauGMn1ZT+Tpq4YyfVlP9KmrhjJ9WU/k6auGMn1dT8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADSpq4YyfVlPwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAk6auGMn1ZT8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAk6auGMn1ZT8=\",\"dtype\":\"float64\",\"shape\":[100]}},\"selected\":{\"id\":\"1335\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1336\",\"type\":\"UnionRenderers\"}},\"id\":\"1304\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1335\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1286\",\"type\":\"BasicTicker\"},{\"attributes\":{\"ticker\":{\"id\":\"1286\",\"type\":\"BasicTicker\"}},\"id\":\"1289\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1336\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_color\":{\"value\":\"#555555\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1305\",\"type\":\"Quad\"},{\"attributes\":{},\"id\":\"1291\",\"type\":\"BasicTicker\"},{\"attributes\":{\"formatter\":{\"id\":\"1331\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1291\",\"type\":\"BasicTicker\"}},\"id\":\"1290\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data_source\":{\"id\":\"1304\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1305\",\"type\":\"Quad\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1306\",\"type\":\"Quad\"},\"selection_glyph\":null,\"view\":{\"id\":\"1308\",\"type\":\"CDSView\"}},\"id\":\"1307\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"1291\",\"type\":\"BasicTicker\"}},\"id\":\"1294\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"1304\",\"type\":\"ColumnDataSource\"}},\"id\":\"1308\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1333\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1298\",\"type\":\"SaveTool\"},{\"attributes\":{\"text\":\"Word Positive/Negative Affinity Distribution\"},\"id\":\"1275\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1283\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1297\",\"type\":\"ResetTool\"},{\"attributes\":{\"formatter\":{\"id\":\"1333\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1286\",\"type\":\"BasicTicker\"}},\"id\":\"1285\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1295\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1281\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1296\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"callback\":null},\"id\":\"1279\",\"type\":\"DataRange1d\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1306\",\"type\":\"Quad\"},{\"attributes\":{\"callback\":null},\"id\":\"1277\",\"type\":\"DataRange1d\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1295\",\"type\":\"PanTool\"},{\"id\":\"1296\",\"type\":\"WheelZoomTool\"},{\"id\":\"1297\",\"type\":\"ResetTool\"},{\"id\":\"1298\",\"type\":\"SaveTool\"}]},\"id\":\"1299\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1331\",\"type\":\"BasicTickFormatter\"}],\"root_ids\":[\"1274\"]},\"title\":\"Bokeh Application\",\"version\":\"1.4.0\"}};\n",
              "  var render_items = [{\"docid\":\"febe4297-df6f-4b07-a174-4e3b85a6c3d6\",\"roots\":{\"1274\":\"05a334cd-d8bb-4b84-bc43-34b902f5758e\"}}];\n",
              "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "\n",
              "  }\n",
              "  if (root.Bokeh !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else {\n",
              "        attempts++;\n",
              "        if (attempts > 100) {\n",
              "          clearInterval(timer);\n",
              "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "        }\n",
              "      }\n",
              "    }, 10, root)\n",
              "  }\n",
              "})(window);"
            ],
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "tags": [],
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "1274"
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWBVTM1VP6fX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frequency_frequency = Counter()\n",
        "\n",
        "for word, cnt in total_count.most_common():\n",
        "    frequency_frequency[cnt] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgZYlRJ8QEaA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "outputId": "c7d334fd-5486-43d2-aaae-b7da803e5719"
      },
      "source": [
        "hist, edges = np.histogram(list(map(lambda x:x[1],frequency_frequency.most_common())), density=True, bins=100, normed=True)\n",
        "\n",
        "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
        "           toolbar_location=\"above\",\n",
        "           title=\"The frequency distribution of the words in our corpus\")\n",
        "p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=\"#555555\")\n",
        "show(p)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: The normed argument is ignored when density is provided. In future passing both will result in an error.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "\n",
              "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "  var JS_MIME_TYPE = 'application/javascript';\n",
              "  var HTML_MIME_TYPE = 'text/html';\n",
              "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    var script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    var cell = handle.cell;\n",
              "\n",
              "    var id = cell.output_area._bokeh_element_id;\n",
              "    var server_id = cell.output_area._bokeh_server_id;\n",
              "    // Clean up Bokeh references\n",
              "    if (id != null && id in Bokeh.index) {\n",
              "      Bokeh.index[id].model.document.clear();\n",
              "      delete Bokeh.index[id];\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            var id = msg.content.text.trim();\n",
              "            if (id in Bokeh.index) {\n",
              "              Bokeh.index[id].model.document.clear();\n",
              "              delete Bokeh.index[id];\n",
              "            }\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    var output_area = handle.output_area;\n",
              "    var output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      var bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      var script_attrs = bk_div.children[0].attributes;\n",
              "      for (var i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      var toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  \n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded() {\n",
              "    var el = document.getElementById(null);\n",
              "    if (el != null) {\n",
              "      el.textContent = \"BokehJS is loading...\";\n",
              "    }\n",
              "    if (root.Bokeh !== undefined) {\n",
              "      if (el != null) {\n",
              "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(display_loaded, 100)\n",
              "    }\n",
              "  }\n",
              "\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
              "        if (callback != null)\n",
              "          callback();\n",
              "      });\n",
              "    } finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.debug(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(css_urls, js_urls, callback) {\n",
              "    if (css_urls == null) css_urls = [];\n",
              "    if (js_urls == null) js_urls = [];\n",
              "\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
              "\n",
              "    function on_load() {\n",
              "      root._bokeh_is_loading--;\n",
              "      if (root._bokeh_is_loading === 0) {\n",
              "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
              "        run_callbacks()\n",
              "      }\n",
              "    }\n",
              "\n",
              "    function on_error() {\n",
              "      console.error(\"failed to load \" + url);\n",
              "    }\n",
              "\n",
              "    for (var i = 0; i < css_urls.length; i++) {\n",
              "      var url = css_urls[i];\n",
              "      const element = document.createElement(\"link\");\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.rel = \"stylesheet\";\n",
              "      element.type = \"text/css\";\n",
              "      element.href = url;\n",
              "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
              "      document.body.appendChild(element);\n",
              "    }\n",
              "\n",
              "    for (var i = 0; i < js_urls.length; i++) {\n",
              "      var url = js_urls[i];\n",
              "      var element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "  };\n",
              "\n",
              "  function inject_raw_css(css) {\n",
              "    const element = document.createElement(\"style\");\n",
              "    element.appendChild(document.createTextNode(css));\n",
              "    document.body.appendChild(element);\n",
              "  }\n",
              "\n",
              "  \n",
              "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
              "  var css_urls = [];\n",
              "  \n",
              "\n",
              "  var inline_js = [\n",
              "    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "    function(Bokeh) {\n",
              "    \n",
              "    \n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    \n",
              "    if (root.Bokeh !== undefined || force === true) {\n",
              "      \n",
              "    for (var i = 0; i < inline_js.length; i++) {\n",
              "      inline_js[i].call(root, root.Bokeh);\n",
              "    }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(css_urls, js_urls, function() {\n",
              "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "  <div class=\"bk-root\" id=\"1ca9a2aa-bd28-4a1c-a0a9-20d32f65fa8f\" data-root-id=\"1176\"></div>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function embed_document(root) {\n",
              "    \n",
              "  var docs_json = {\"01758561-4464-42b8-93a4-5b574b8fae2b\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1187\",\"type\":\"LinearAxis\"}],\"center\":[{\"id\":\"1191\",\"type\":\"Grid\"},{\"id\":\"1196\",\"type\":\"Grid\"}],\"left\":[{\"id\":\"1192\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"1209\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1177\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1201\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"1179\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1183\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1181\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1185\",\"type\":\"LinearScale\"}},\"id\":\"1176\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1193\",\"type\":\"BasicTicker\"},{\"attributes\":{\"ticker\":{\"id\":\"1188\",\"type\":\"BasicTicker\"}},\"id\":\"1191\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1230\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1226\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1228\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1197\",\"type\":\"PanTool\"},{\"id\":\"1198\",\"type\":\"WheelZoomTool\"},{\"id\":\"1199\",\"type\":\"ResetTool\"},{\"id\":\"1200\",\"type\":\"SaveTool\"}]},\"id\":\"1201\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1231\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"data_source\":{\"id\":\"1206\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1207\",\"type\":\"Quad\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1208\",\"type\":\"Quad\"},\"selection_glyph\":null,\"view\":{\"id\":\"1210\",\"type\":\"CDSView\"}},\"id\":\"1209\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"1206\",\"type\":\"ColumnDataSource\"}},\"id\":\"1210\",\"type\":\"CDSView\"},{\"attributes\":{\"text\":\"The frequency distribution of the words in our corpus\"},\"id\":\"1177\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1185\",\"type\":\"LinearScale\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1208\",\"type\":\"Quad\"},{\"attributes\":{},\"id\":\"1197\",\"type\":\"PanTool\"},{\"attributes\":{\"formatter\":{\"id\":\"1228\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1188\",\"type\":\"BasicTicker\"}},\"id\":\"1187\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1199\",\"type\":\"ResetTool\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"1193\",\"type\":\"BasicTicker\"}},\"id\":\"1196\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null},\"id\":\"1179\",\"type\":\"DataRange1d\"},{\"attributes\":{\"callback\":null},\"id\":\"1181\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1200\",\"type\":\"SaveTool\"},{\"attributes\":{\"callback\":null,\"data\":{\"left\":{\"__ndarray__\":\"AAAAAAAA8D/NzMzMzFhxQM3MzMzMUIFANDMzMzP1iUDNzMzMzEyRQAAAAAAAn5VANDMzMzPxmUBnZmZmZkOeQM3MzMzMSqFAZ2ZmZuZzo0AAAAAAAJ2lQJqZmZkZxqdANDMzMzPvqUDNzMzMTBisQGdmZmZmQa5AAAAAAEA1sEDNzMzMzEmxQJqZmZlZXrJAZ2ZmZuZys0AzMzMzc4e0QAAAAAAAnLVAzczMzIywtkCamZmZGcW3QGdmZmam2bhANDMzMzPuuUAAAAAAwAK7QM3MzMxMF7xAmpmZmdkrvUBnZmZmZkC+QDQzMzPzVL9AAAAAAMA0wEBnZmZmBr/AQM3MzMxMScFAMzMzM5PTwUCamZmZ2V3CQAAAAAAg6MJAZ2ZmZmZyw0DNzMzMrPzDQDMzMzPzhsRAmpmZmTkRxUAAAAAAgJvFQGdmZmbGJcZAzczMzAywxkAzMzMzUzrHQJqZmZmZxMdAAAAAAOBOyEBnZmZmJtnIQM3MzMxsY8lANDMzM7PtyUCamZmZ+XfKQAAAAABAAstAZ2ZmZoaMy0DNzMzMzBbMQDQzMzMTocxAmpmZmVkrzUAAAAAAoLXNQGdmZmbmP85AzczMzCzKzkA0MzMzc1TPQJqZmZm53s9AAAAAAIA00EAzMzMzo3nQQGdmZmbGvtBAmpmZmekD0UDNzMzMDEnRQAAAAAAwjtFAMzMzM1PT0UBnZmZmdhjSQJqZmZmZXdJAzczMzLyi0kAAAAAA4OfSQDMzMzMDLdNAZ2ZmZiZy00CamZmZSbfTQM3MzMxs/NNAAAAAAJBB1EAzMzMzs4bUQGdmZmbWy9RAmpmZmfkQ1UDNzMzMHFbVQAAAAABAm9VAMzMzM2Pg1UBnZmZmhiXWQJqZmZmpatZAzczMzMyv1kAAAAAA8PTWQDMzMzMTOtdAZ2ZmZjZ/10CamZmZWcTXQM3MzMx8CdhAAAAAAKBO2EAzMzMzw5PYQGdmZmbm2NhAmpmZmQke2UDNzMzMLGPZQAAAAABQqNlANDMzM3Pt2UBnZmZmljLaQJqZmZm5d9pAzczMzNy82kA=\",\"dtype\":\"float64\",\"shape\":[100]},\"right\":{\"__ndarray__\":\"zczMzMxYcUDNzMzMzFCBQDQzMzMz9YlAzczMzMxMkUAAAAAAAJ+VQDQzMzMz8ZlAZ2ZmZmZDnkDNzMzMzEqhQGdmZmbmc6NAAAAAAACdpUCamZmZGcanQDQzMzMz76lAzczMzEwYrEBnZmZmZkGuQAAAAABANbBAzczMzMxJsUCamZmZWV6yQGdmZmbmcrNAMzMzM3OHtEAAAAAAAJy1QM3MzMyMsLZAmpmZmRnFt0BnZmZmptm4QDQzMzMz7rlAAAAAAMACu0DNzMzMTBe8QJqZmZnZK71AZ2ZmZmZAvkA0MzMz81S/QAAAAADANMBAZ2ZmZga/wEDNzMzMTEnBQDMzMzOT08FAmpmZmdldwkAAAAAAIOjCQGdmZmZmcsNAzczMzKz8w0AzMzMz84bEQJqZmZk5EcVAAAAAAICbxUBnZmZmxiXGQM3MzMwMsMZAMzMzM1M6x0CamZmZmcTHQAAAAADgTshAZ2ZmZibZyEDNzMzMbGPJQDQzMzOz7clAmpmZmfl3ykAAAAAAQALLQGdmZmaGjMtAzczMzMwWzEA0MzMzE6HMQJqZmZlZK81AAAAAAKC1zUBnZmZm5j/OQM3MzMwsys5ANDMzM3NUz0CamZmZud7PQAAAAACANNBAMzMzM6N50EBnZmZmxr7QQJqZmZnpA9FAzczMzAxJ0UAAAAAAMI7RQDMzMzNT09FAZ2ZmZnYY0kCamZmZmV3SQM3MzMy8otJAAAAAAODn0kAzMzMzAy3TQGdmZmYmctNAmpmZmUm300DNzMzMbPzTQAAAAACQQdRAMzMzM7OG1EBnZmZm1svUQJqZmZn5ENVAzczMzBxW1UAAAAAAQJvVQDMzMzNj4NVAZ2ZmZoYl1kCamZmZqWrWQM3MzMzMr9ZAAAAAAPD01kAzMzMzEzrXQGdmZmY2f9dAmpmZmVnE10DNzMzMfAnYQAAAAACgTthAMzMzM8OT2EBnZmZm5tjYQJqZmZkJHtlAzczMzCxj2UAAAAAAUKjZQDQzMzNz7dlAZ2ZmZpYy2kCamZmZuXfaQM3MzMzcvNpAAAAAAAAC20A=\",\"dtype\":\"float64\",\"shape\":[100]},\"top\":{\"__ndarray__\":\"TDhFg5YVbT+JTZDME4n7PtMKDQpDB+Y+1QoNCkMH1j7VCg0KQwfWPgAAAAAAAAAA1QoNCkMHxj7VCg0KQwfGPgAAAAAAAAAA2goNCkMHxj4AAAAAAAAAAAAAAAAAAAAA2goNCkMHxj4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA5QoNCkMHxj4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOUKDQpDB8Y+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA5QoNCkMHxj4=\",\"dtype\":\"float64\",\"shape\":[100]}},\"selected\":{\"id\":\"1230\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1231\",\"type\":\"UnionRenderers\"}},\"id\":\"1206\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1188\",\"type\":\"BasicTicker\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_color\":{\"value\":\"#555555\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1207\",\"type\":\"Quad\"},{\"attributes\":{},\"id\":\"1198\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1183\",\"type\":\"LinearScale\"},{\"attributes\":{\"formatter\":{\"id\":\"1226\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1193\",\"type\":\"BasicTicker\"}},\"id\":\"1192\",\"type\":\"LinearAxis\"}],\"root_ids\":[\"1176\"]},\"title\":\"Bokeh Application\",\"version\":\"1.4.0\"}};\n",
              "  var render_items = [{\"docid\":\"01758561-4464-42b8-93a4-5b574b8fae2b\",\"roots\":{\"1176\":\"1ca9a2aa-bd28-4a1c-a0a9-20d32f65fa8f\"}}];\n",
              "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "\n",
              "  }\n",
              "  if (root.Bokeh !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else {\n",
              "        attempts++;\n",
              "        if (attempts > 100) {\n",
              "          clearInterval(timer);\n",
              "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "        }\n",
              "      }\n",
              "    }, 10, root)\n",
              "  }\n",
              "})(window);"
            ],
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "tags": [],
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "1176"
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dodSauFxRDEl",
        "colab_type": "text"
      },
      "source": [
        "to run Predictions on new reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyGQPWCwQGsm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "96203784-481b-485d-b83f-7a1afa64c4e3"
      },
      "source": [
        "#Display the original labels of some reviews\n",
        "\n",
        "pretty_print_review_and_label(2137)\n",
        "pretty_print_review_and_label(12816)\n",
        "pretty_print_review_and_label(6267)\n",
        "pretty_print_review_and_label(21934)\n",
        "pretty_print_review_and_label(5297)\n",
        "pretty_print_review_and_label(4998)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NEGATIVE\t:\tthis movie is terrible but it has some good effects .  \n",
            "POSITIVE\t:\tadrian pasdar is excellent is this film . he makes a fascinating woman .  \n",
            "NEGATIVE\t:\tcomment this movie is impossible . is terrible  very improbable  bad interpretation e direction . not look       \n",
            "POSITIVE\t:\texcellent episode movie ala pulp fiction .  days   suicides . it doesnt get more depressing than this . movie rating     music rating       \n",
            "NEGATIVE\t:\tif you haven  t seen this  it  s terrible . it is pure trash . i saw this about   years ago  and i  m still screwed up from it .  \n",
            "POSITIVE\t:\tthis schiffer guy is a real genius  the movie is of excellent quality and both entertaining and educating .  br    br   i didn  t know what a weather girl was before i learned it here .  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH-FwdDyRhA1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44205611-c6d5-43d4-8c94-1e8a8df7088e"
      },
      "source": [
        "#Display the model prediction\n",
        "\n",
        "mlp.run(reviews_list[2137])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NEGATIVE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRutw5okR2Ds",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdd66edb-6a7b-44af-e6a8-d75b934c3e2c"
      },
      "source": [
        "mlp.run(reviews_list[12816])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'POSITIVE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w9TvotjSCke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6345c8ce-ea42-437d-c769-9ee2ede3727f"
      },
      "source": [
        "mlp.run(reviews_list[6267])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NEGATIVE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPKZ-0b1SGSd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0bdb906-61b9-4e5a-fe0b-6c5c697fd5ef"
      },
      "source": [
        "mlp.run(reviews_list[21934])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'POSITIVE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpKO6mqoSJrB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4455ac3-cdf1-4339-d37a-053820e5159b"
      },
      "source": [
        "#This one was wrongly classified\n",
        "mlp.run(reviews_list[5297])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'POSITIVE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5A-Pf4ZSLjZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "243822dc-c8c7-41ad-ebdb-ed4960523919"
      },
      "source": [
        "mlp.run(reviews_list[4998])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'POSITIVE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVFm6mwdSPEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}